# ACE-Step Discord Radio Bot Configuration
# Copy this file to .env and fill in your values

# ================================
# REQUIRED SETTINGS
# ================================

# Discord Bot Token - Get from: https://discord.com/developers/applications
DISCORD_TOKEN=your_discord_bot_token_here

# ================================
# 8GB VRAM OPTIMIZATION (Recommended)
# ================================

# Enable CPU offload for ACE-Step model (saves 4-6GB VRAM)
CPU_OFFLOAD=true

# Official 8GB optimization from ACE-Step team
TORCH_COMPILE=true

# Improved memory efficiency
OVERLAPPED_DECODE=true

# ================================
# LLM CONFIGURATION
# ================================

# LLM Model name (recommended for 8GB systems)
LLM_MODEL_NAME=Huihui-gemma-3n-E4B-it-abliterated.Q4_K_M.gguf

# GPU layers for LLM (-1 = use all available GPU memory after ACE-Step)
LLM_GPU_LAYERS=-1

# LLM context size
LLM_CONTEXT_SIZE=4096

# ================================
# AUDIO GENERATION SETTINGS
# ================================

# Default track duration in seconds (60s recommended for 8GB systems)
DEFAULT_DURATION=60

# Maximum allowed track duration in seconds
MAX_LENGTH_MAX=300

# Maximum file size for uploads (8MB)
MAX_FILE_SIZE=8388608

# ================================
# PERFORMANCE TUNING
# ================================

# GPU device to use (0 for first GPU, -1 for CPU)
CUDA_VISIBLE_DEVICES=0

# Batch size for generation (1 recommended for memory efficiency)
BATCH_SIZE=1

# Queue buffer size (2-4 recommended)
BUFFER_SIZE=2

# ================================
# BOT BEHAVIOR SETTINGS
# ================================

# Maximum number of Discord servers
MAX_GUILDS=100

# Command prefix for text commands (slash commands don't need this)
COMMAND_PREFIX=!

# Auto-generate next track when queue is low
AUTO_GENERATE=true

# Enable debug logging
DEBUG_MODE=false

# ================================
# ADVANCED SETTINGS (Optional)
# ================================

# Custom model paths (leave empty to use defaults)
# ACE_CHECKPOINT_PATH=./checkpoints
# LLM_MODEL_PATH=./models

# Memory management
# TORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Additional CUDA settings for compatibility
# PYTORCH_CUDA_ALLOC_CONF=garbage_collection_threshold:0.6,max_split_size_mb:128
